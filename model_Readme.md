# Image to Text Model
This project implements a BLIP (Bootstrapped Language-Image Pre-training) model. 
It allows to input an image (via URL), and the model generates captions describing the content of the image.
